# src/train.py
import os
import torch
import mlflow
import hashlib
import yaml
from torch.utils.data import DataLoader, TensorDataset
from data import load_data, tokenize_data
from model import SimpleClassifier
from evaluate import evaluate_model
import os
import shutil
import subprocess
def run_dvc_cmd(cmd):
    os.environ['GIT_TRACE'] = '1'  # çœ‹ Git å†…éƒ¨æ‰§è¡Œæµ
    os.environ['GIT_TRACE_SETUP'] = '1'  # çœ‹å·¥ä½œåŒº/ä»“åº“è·¯å¾„
    print('which git  :', shutil.which('git'))
    print('cwd        :', os.getcwd())
    print('exists Git :', os.path.exists(shutil.which('git')))
    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
    print(f'>>> {cmd}')
    print(f'  returncode : {result.returncode}')
    print(f'  stdout     : {repr(result.stdout)}')
    print(f'  stderr     : {repr(result.stderr)}')
    if result.returncode != 0:
        raise Exception(f"Command failed: {cmd}\n{result.stderr}")
    print(result.stdout)
# def run_dvc_cmd(cmd):
#     # ç”¨ bash ç™»å½•æ¨¡å¼ï¼ŒåŠ è½½ /etc/profile å’Œ ~/.bashrc
#     result = subprocess.run(
#         ['bash', '-l', '-c', cmd],
#         capture_output=True,
#         text=True,
#         cwd='/media/administrator/Data2/wzy/xx/llm-ops'
#     )
#     print('>>>', cmd)
#     print('returncode:', result.returncode)
#     print('stdout:', repr(result.stdout))
#     print('stderr:', repr(result.stderr))
#     if result.returncode != 0:
#         raise Exception(f"Command failed: {cmd}\n{result.stderr}")
#     print(result.stdout)

def check_data_changed():
    """æ£€æŸ¥ DVC æ•°æ®æ˜¯å¦æœ‰æ›´æ–°"""
    result = subprocess.run("dvc status", shell=True, capture_output=True, text=True)
    if "new" in result.stdout or "modified" in result.stdout:
        print("âœ… Data has changed, proceed with training.")
        return True
    else:
        print("ğŸš« No data change detected, skip training.")
        return False

def train():
    # --- 1. æ£€æŸ¥æ•°æ®æ˜¯å¦æ›´æ–° ---
    if not check_data_changed():
        return {"status": "skipped", "reason": "no_data_change"}

    # --- 2. åŠ è½½å‚æ•° ---
    with open("params.yaml") as f:
        params = yaml.safe_load(f)

    model_name = params['model']['name']
    num_labels = params['model']['num_labels']
    epochs = params['training']['epochs']
    batch_size = params['training']['batch_size']
    lr = params['training']['learning_rate']
    max_length = params['data']['max_length']

    # --- 3. å‡†å¤‡æ•°æ® ---
    df = load_data(params['data']['path'])
    encodings, labels = tokenize_data(df, model_name, max_length)

    dataset = TensorDataset(
        encodings['input_ids'],
        encodings['attention_mask'],
        labels
    )
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    # --- 4. è®¾ç½®è®¾å¤‡ ---
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # --- 5. åŠ è½½æ¨¡å‹ï¼ˆæ”¯æŒå¢é‡è®­ç»ƒï¼‰---
    model_path = "models/latest_model.pth"
    if os.path.exists(model_path):
        print(f"ğŸ” Loading existing model from {model_path}")
        model = SimpleClassifier(model_name, num_labels)
        model.load_state_dict(torch.load(model_path))
    else:
        print("ğŸ†• Initializing new model")
        model = SimpleClassifier(model_name, num_labels)
    model.to(device)
    lr = float(lr)
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)

    # --- 6. MLflow å¼€å§‹è®°å½• ---
    mlflow.set_tracking_uri("file:./mlruns")  # æœ¬åœ°
    mlflow.set_experiment("nlp-text-classification")

    with mlflow.start_run() as run:
        # è®°å½•å‚æ•°
        mlflow.log_params({
            "model_name": model_name,
            "epochs": epochs,
            "batch_size": batch_size,
            "learning_rate": lr,
            "max_length": max_length
        })

        # è®­ç»ƒå¾ªç¯
        for epoch in range(epochs):

            model.train()
            total_loss = 0
            for batch in dataloader:
                #print(batch)
                input_ids = batch[0].to(device)
                attention_mask = batch[1].to(device)
                labels = batch[2].to(device)

                optimizer.zero_grad()
                outputs = model(input_ids, attention_mask)
                loss = torch.nn.functional.cross_entropy(outputs, labels)
                loss.backward()
                optimizer.step()

                total_loss += loss.item()

            avg_loss = total_loss / len(dataloader)
            mlflow.log_metric("loss", avg_loss, step=epoch)
            print(f"epoch[{epoch}] avg_loss[{avg_loss}]")
        # --- 7. è¯„ä¼°æ¨¡å‹ ---
        test_dataloader = DataLoader(dataset, batch_size=batch_size)  # ç®€åŒ–ï¼šç”¨å…¨é‡æ•°æ®è¯„ä¼°
        auc_score = evaluate_model(model, test_dataloader, device)

        # --- 8. æ¨¡å‹é—¨ç¦ï¼šAUC < 0.8 ä¸ä¿å­˜ ---
        if auc_score < 0.8:
            print(f"âŒ AUC={auc_score:.3f} < 0.8, skipping model save and DVC commit.")
            return {"status": "rejected", "auc": auc_score}

        # --- 9. ä¿å­˜æ¨¡å‹ + è®¡ç®— MD5 ---
        torch.save(model.state_dict(), model_path)
        hash_md5 = hashlib.md5()
        with open(model_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_md5.update(chunk)
        model_md5 = hash_md5.hexdigest()
        with open("models/latest_model.md5", "w") as f:
            f.write(model_md5)

        mlflow.log_metric("final_auc", auc_score)
        mlflow.log_param("model_md5", model_md5)
        mlflow.pytorch.log_model(model, "model")  # ä¿å­˜æ¨¡å‹åˆ° MLflow

        # --- 10. æ³¨å†Œæ¨¡å‹åˆ° MLflow Model Registry ---
        model_uri = f"runs:/{run.info.run_id}/model"
        registered_model_name = "NLPTextClassifier"
        try:
            mlflow.register_model(model_uri, registered_model_name)
        except Exception as e:
            print(f"Model may already exist: {e}")

        print(f"âœ… Model trained, AUC={auc_score:.3f}, MD5={model_md5}")

        # --- 11. DVC æäº¤ ---
        run_dvc_cmd("dvc add models/latest_model.pth")
        run_dvc_cmd("dvc add models/latest_model.md5")
        run_dvc_cmd("dvc add reports/roc_curve.png")
        os.system(f'git commit -m "feat: trained model with AUC={auc_score:.3f}, MD5={model_md5}" --no-verify')  # è·³è¿‡é’©å­
        # run_dvc_cmd("git add models/latest_model.pth.dvc models/latest_model.md5.dvc reports/roc_curve.png.dvc params.yaml")
        # run_dvc_cmd("git add models/latest_model.pth.dvc models/latest_model.md5.dvc reports/roc_curve.png.dvc")
        # run_dvc_cmd(f'git commit -m "feat: trained model with AUC={auc_score:.3f}, MD5={model_md5}"')

        return {"status": "success", "auc": auc_score, "md5": model_md5}

if __name__ == '__main__':
    train()